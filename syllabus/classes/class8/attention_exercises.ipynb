{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import torch\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[=================---------------------------------] 35.5% 23.4/66.0MB downloadedIOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n[==================================================] 100.0% 66.0/66.0MB downloaded\n"
    }
   ],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "19.30446\n5.5297327\n4.48352\n"
    }
   ],
   "source": [
    "#Similar words: chair and chairs\n",
    "#Dissimilar word: kissing\n",
    "print(np.dot(model[\"chair\"], model[\"chairs\"]))\n",
    "print(np.dot(model[\"chair\"], model[\"kissing\"]))\n",
    "print(np.dot(model[\"chairs\"], model[\"kissing\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.array([model[\"chair\"], \n",
    "              model[\"chairs\"], \n",
    "              model[\"kissing\"]])\n",
    "ET = E.transpose()\n",
    "EET = E @ ET"
   ]
  },
  {
   "source": [
    "Values in the diagonal is the dot product between each vector and itself, or the length of the vector (Euclidian norm)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = torch.nn.Softmax(dim=1)\n",
    "soft_max = soft(torch.tensor(EET))\n",
    "# print(torch.tensor(EET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_max = soft_max/sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = soft_max @ E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-1.0443e+00  4.9202e-01 -7.5978e-01 -3.9224e-01  8.1217e-01 -3.9287e-02\n   1.6706e-02 -6.8629e-01 -7.8359e-02 -1.3214e+00 -1.5354e-01  2.0438e-01\n  -4.6503e-01  1.2145e+00 -1.8217e-01  2.7451e-01 -2.4086e-01  7.1145e-01\n   3.2470e-01 -7.1320e-01  6.6721e-01  7.1307e-01 -1.0394e-01 -3.8439e-01\n  -2.0260e-01 -1.4419e+00  4.2644e-01  5.9436e-01 -1.3615e+00  1.3784e-03\n   1.8734e+00 -1.1334e-01 -8.8115e-01 -2.1715e-01 -5.6606e-01  1.4152e-01\n   2.7673e-01  9.9962e-01  1.0567e+00 -2.9428e-01 -3.1390e-01  1.2729e-01\n  -5.4363e-01  3.9652e-01 -3.2527e-01  3.0536e-01  1.5128e-01 -1.0889e+00\n  -2.0867e-01 -5.2605e-02]\n [-4.4667e-01  2.2689e-01 -3.3492e-01 -4.4306e-01  6.6352e-01 -1.7471e-02\n  -2.4326e-01 -1.3830e+00 -2.2056e-01 -1.5313e+00 -1.0970e+00 -1.0836e-01\n  -2.2645e-03  1.4806e+00 -2.8026e-01  1.7097e-01  2.1776e-01  6.5824e-01\n   9.2905e-01 -1.8841e+00  5.5043e-01  7.3985e-01 -2.7086e-01 -2.8554e-01\n  -5.8936e-01 -4.6107e-01  3.0422e-01  8.4354e-01 -1.2253e+00 -1.6104e-01\n   1.4946e+00  4.9215e-01 -6.5197e-01  3.5423e-01 -2.7853e-01  8.3649e-01\n   1.5340e-01  7.6195e-01  5.3832e-01  2.2161e-01 -2.3658e-01  6.6593e-01\n   6.5934e-02  8.8077e-01  1.3173e-01  9.8167e-01 -5.1037e-01 -8.5798e-01\n  -5.0460e-01 -6.5854e-01]\n [ 1.6891e-01  7.8732e-01 -5.7129e-01 -7.0122e-01  6.7590e-01  1.2712e+00\n   7.1601e-02 -1.5691e-01 -1.7575e-01  1.2385e-01 -3.5003e-01  2.5820e-03\n  -8.3116e-02  4.0933e-01  6.9422e-01 -1.5831e-01 -5.8150e-01 -5.4797e-02\n   3.7882e-02 -1.4281e-01  1.4618e-01  1.5445e+00  8.4138e-01  8.3994e-01\n   9.1300e-01 -8.9139e-01  3.1637e-01  8.7196e-01  4.2712e-01 -1.2023e+00\n   3.7586e-01  7.3859e-01 -2.5630e-01  1.9562e-01 -7.3081e-01  8.5503e-03\n   5.8206e-02 -3.9814e-01 -5.1849e-01  1.4385e-02  1.7283e-01  8.6704e-02\n  -1.6778e-01  4.7101e-01  1.0014e+00 -1.3483e+00  5.1915e-01 -1.5475e+00\n   5.7574e-02 -4.5313e-01]]\n"
    }
   ],
   "source": [
    "attention\n",
    "print(E)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitdfd3d3adc17149d59d02ab93a296c404",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}